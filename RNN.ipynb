{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Author: Ali Akbar Halvaei \n",
    "* email: ali.akbarhalvaei@studio.unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "In this notebook, we want to design one RNN encoder-decoder with the aim of ordering unordered sentences. So, there are three main steps in this notebook:\n",
    "\n",
    "* Downloading the dataset\n",
    "* Preparing the dataset\n",
    "* Design the model\n",
    "\n",
    "For this task, transformers have better performance; however, with the purpose of learning about how RNN encoder-decoder works, I have decided to design this model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is among the sequence-to-sequence task. Recently, most of the task in this category have been done using by either Transformers or Encoder-Decoder architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:08:21.417901Z",
     "iopub.status.busy": "2024-06-12T01:08:21.417575Z",
     "iopub.status.idle": "2024-06-12T01:11:24.807859Z",
     "shell.execute_reply": "2024-06-12T01:11:24.806805Z",
     "shell.execute_reply.started": "2024-06-12T01:08:21.417870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 01:08:24.890022: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-12 01:08:24.890117: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-12 01:08:25.021734: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ef6d4876af454090f2a4b7730a6f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa1efd1e9c7459e98b007f2abb9f42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/11.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abcb44aa6f747eba6134aeeb2019af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8d7814e9084971b0b9a2dbaf1ffd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1020868 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7feee33e472d46c49b932789362e40d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1020868 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from keras.layers import TextVectorization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load dataset\n",
    "ds = load_dataset('generics_kb', trust_remote_code=True)['train']\n",
    "\n",
    "# Filter sentences longer than 8 words\n",
    "ds = ds.filter(lambda row: len(row[\"generic_sentence\"].split(\" \")) > 8)\n",
    "\n",
    "# Prepare corpus with special tokens\n",
    "corpus = ['<start> ' + row['generic_sentence'].replace(\",\", \" <comma>\") + ' <end>' for row in ds]\n",
    "corpus = np.array(corpus)\n",
    "\n",
    "# Define TextVectorization\n",
    "tokenizer = TextVectorization(max_tokens=10000, standardize=\"lower_and_strip_punctuation\", encoding=\"utf-8\")\n",
    "tokenizer.adapt(corpus)\n",
    "\n",
    "# Define the TextDetokenizer class\n",
    "class TextDetokenizer:\n",
    "    def __init__(self, vectorize_layer):\n",
    "        self.vectorize_layer = vectorize_layer\n",
    "        vocab = self.vectorize_layer.get_vocabulary()\n",
    "        self.index_to_word = {index: word for index, word in enumerate(vocab)}\n",
    "\n",
    "    def __detokenize_tokens(self, tokens):\n",
    "        def check_token(t):\n",
    "            if t == 3:\n",
    "                return \"<start>\"\n",
    "            elif t == 2:\n",
    "                return \"<end>\"\n",
    "            elif t == 7:\n",
    "                return \"<comma>\"\n",
    "            else:\n",
    "                return self.index_to_word.get(t, '[UNK]')\n",
    "\n",
    "        return ' '.join([check_token(token) for token in tokens if token != 0])\n",
    "\n",
    "    def __call__(self, batch_tokens):\n",
    "        return [self.__detokenize_tokens(tokens) for tokens in batch_tokens]\n",
    "\n",
    "# Initialize the detokenizer\n",
    "detokenizer = TextDetokenizer(tokenizer)\n",
    "\n",
    "# Tokenize the corpus\n",
    "sentences = tokenizer(corpus).numpy()\n",
    "\n",
    "# Filter out sentences with unknown tokens\n",
    "mask = np.sum((sentences == 1), axis=1) >= 1\n",
    "original_data = np.delete(sentences, mask, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:11:42.290357Z",
     "iopub.status.busy": "2024-06-12T01:11:42.289726Z",
     "iopub.status.idle": "2024-06-12T01:11:42.371582Z",
     "shell.execute_reply": "2024-06-12T01:11:42.370763Z",
     "shell.execute_reply.started": "2024-06-12T01:11:42.290326Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, data, batch_size=32, shuffle=True, seed=42):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        data_batch = np.array([self.data[k] for k in indexes])\n",
    "        #copy of ordered sequences\n",
    "        result = np.copy(data_batch)\n",
    "        #shuffle only the relevant positions for each batch\n",
    "        for i in range(data_batch.shape[0]):\n",
    "            np.random.shuffle(data_batch[i,1:data_batch[i].argmin() - 1])\n",
    "\n",
    "        return data_batch , result\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        if self.shuffle:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed)\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# Shuffle and split the dataset into training and test sets\n",
    "np.random.seed(42)\n",
    "shuffled_indices = np.random.permutation(len(original_data))\n",
    "shuffled_data = original_data[shuffled_indices]\n",
    "\n",
    "train_data = shuffled_data[:220000]\n",
    "test_data = shuffled_data[220000:]\n",
    "test_generator = DataGenerator(test_data, batch_size=32)\n",
    "train_generator = DataGenerator(train_data, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(original_data[:220000])\n",
    "test_generator = DataGenerator(original_data[220000:])\n",
    "x, y = test_generator.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:11:47.346397Z",
     "iopub.status.busy": "2024-06-12T01:11:47.346014Z",
     "iopub.status.idle": "2024-06-12T01:11:47.353473Z",
     "shell.execute_reply": "2024-06-12T01:11:47.352545Z",
     "shell.execute_reply.started": "2024-06-12T01:11:47.346356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  <start> wind energy is the one of the most inexpensive forms of energy on the market <end>\n",
      "shuffled:  <start> the on is the wind of forms market energy of energy inexpensive most the one <end>\n",
      "\n",
      "\n",
      "original:  <start> tropical rainforests contain many diverse species <comma> many of which are found nowhere else <end>\n",
      "shuffled:  <start> species tropical are else many nowhere many rainforests of contain found which <comma> diverse <end>\n",
      "\n",
      "\n",
      "original:  <start> urban environments differ from agricultural and wild lands in many respects <end>\n",
      "shuffled:  <start> urban in and wild lands environments respects many from agricultural differ <end>\n",
      "\n",
      "\n",
      "original:  <start> water conservation is one important way to stretch existing water supplies <end>\n",
      "shuffled:  <start> water supplies to conservation water stretch is important way existing one <end>\n",
      "\n",
      "\n",
      "original:  <start> urban life is concentrated in the capital <comma> whose population is mostly engaged in commerce <end>\n",
      "shuffled:  <start> is in life whose engaged in <comma> capital urban population is the commerce concentrated mostly <end>\n",
      "\n",
      "\n",
      "original:  <start> willow roots are excellent at holding the soil in the banks together <end>\n",
      "shuffled:  <start> soil the together excellent at banks holding roots in the are willow <end>\n",
      "\n",
      "\n",
      "original:  <start> wind is caused by uneven heating and cooling of the earths surface and by the earths rotation <end>\n",
      "shuffled:  <start> heating caused surface the the by by and earths of is earths and cooling rotation uneven wind <end>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = detokenizer(x)\n",
    "b = detokenizer(y)\n",
    "\n",
    "for i in range(7):\n",
    "    print(\"original: \", b[i])\n",
    "    print(\"shuffled: \", a[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to using Encoder-Decoder structures, we are dealing with 3 data for the model:\n",
    "\n",
    "1. Encoder input\n",
    "2. Decoder input\n",
    "3. Decoder target\n",
    "\n",
    "In our task, encoder input is the shuffled data, and decoder input and output are the ordered data with a little difference.\n",
    "For Encoder input, the data does not include our special words: **'start', 'end'**\n",
    "\n",
    "On the other hand, The decoder input contain **'start'** but does not contain **'end'**. The reason behind is that after training the model, we receive encoder input and based on the context data(provided by the encoder), we predict decoder values token by token.\n",
    "\n",
    "Finally, Decoder output does not contain **'start'** but contains **'end'**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:18.885876Z",
     "iopub.status.busy": "2024-06-12T02:59:18.885479Z",
     "iopub.status.idle": "2024-06-12T02:59:18.939341Z",
     "shell.execute_reply": "2024-06-12T02:59:18.938411Z",
     "shell.execute_reply.started": "2024-06-12T02:59:18.885848Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 28\n",
    "\n",
    "\n",
    "tds = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(BATCH_SIZE, MAX_LENGTH), dtype=tf.int32), \n",
    "        tf.TensorSpec(shape=(BATCH_SIZE, MAX_LENGTH), dtype=tf.int32)   \n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "test_tds = tf.data.Dataset.from_generator(\n",
    "    lambda: test_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(BATCH_SIZE, MAX_LENGTH), dtype=tf.int32),  \n",
    "        tf.TensorSpec(shape=(BATCH_SIZE, MAX_LENGTH), dtype=tf.int32)   \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why I loaded data into train and test generator and then I change their shape?\n",
    "\n",
    "\n",
    "class DataGenerator has been given by the challenge provider, so I was not supposed to change it. However, I did not like to have data with specific batch size because I could not change the batch size during training phase to find the best batch size for myself. Thus, I have decided to load them into other arrays for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:19.024707Z",
     "iopub.status.busy": "2024-06-12T02:59:19.024063Z",
     "iopub.status.idle": "2024-06-12T02:59:24.654913Z",
     "shell.execute_reply": "2024-06-12T02:59:24.653915Z",
     "shell.execute_reply.started": "2024-06-12T02:59:19.024680Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = list()\n",
    "dec = list()\n",
    "\n",
    "\n",
    "for i, j in tds:\n",
    "    enc.append(i)\n",
    "    dec.append(j)\n",
    "\n",
    "\n",
    "\n",
    "encoder_inputs_data = tf.convert_to_tensor(enc)\n",
    "decoder_inputs_data = tf.convert_to_tensor(dec)\n",
    "decoder_target_data = decoder_inputs_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:24.657039Z",
     "iopub.status.busy": "2024-06-12T02:59:24.656753Z",
     "iopub.status.idle": "2024-06-12T02:59:25.166432Z",
     "shell.execute_reply": "2024-06-12T02:59:25.165567Z",
     "shell.execute_reply.started": "2024-06-12T02:59:24.657015Z"
    }
   },
   "outputs": [],
   "source": [
    "enc_test = []\n",
    "dec_test = []\n",
    "\n",
    "for i, j in test_tds:\n",
    "    enc_test.append(i)\n",
    "    dec_test.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:25.167956Z",
     "iopub.status.busy": "2024-06-12T02:59:25.167687Z",
     "iopub.status.idle": "2024-06-12T02:59:25.175687Z",
     "shell.execute_reply": "2024-06-12T02:59:25.174757Z",
     "shell.execute_reply.started": "2024-06-12T02:59:25.167933Z"
    }
   },
   "outputs": [],
   "source": [
    "#as mentioned encoder should not contain <start> and <end>, so this function removes those words from our encoder input data\n",
    "\n",
    "def encoder_input_preparation(tensor, END_INDEX = 2):\n",
    "    \n",
    "    shifted_tensor = np.zeros_like(tensor)\n",
    "    for i in range(tensor.shape[0]):\n",
    "        # Shift elements to the left and drop the first element\n",
    "        shifted_tensor[i, :-1] = tensor[i, 1:]\n",
    "        # Replace 2 with 0\n",
    "        shifted_tensor[i] = np.where(shifted_tensor[i] == END_INDEX, 0, shifted_tensor[i])\n",
    "    return shifted_tensor\n",
    "\n",
    "\n",
    "#decoder input data should not contain <end> and this function removes them for us\n",
    "def decoder_input_preparation(tensor, END_INDEX = 2):\n",
    "    tensor[i] = np.where(tensor[i] == END_INDEX , 0, tensor[i])\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:25.177855Z",
     "iopub.status.busy": "2024-06-12T02:59:25.177587Z",
     "iopub.status.idle": "2024-06-12T02:59:27.009662Z",
     "shell.execute_reply": "2024-06-12T02:59:27.008703Z",
     "shell.execute_reply.started": "2024-06-12T02:59:25.177832Z"
    }
   },
   "outputs": [],
   "source": [
    "#as the given data is in the shape of 6875,32,28 , I did not have the freedome to change the batch_size to see the performance on different batch_sizes\n",
    "#Thus, I decided to reshape them so that during training I can change different batch sizes\n",
    "encoder_inputs_data = np.array(enc).reshape(220000, 28)\n",
    "encoder_inputs_data = encoder_input_preparation(encoder_inputs_data)\n",
    "\n",
    "decoder_inputs_data = np.array(dec).reshape(220000, 28)\n",
    "decoder_inputs_data = decoder_input_preparation(decoder_inputs_data)\n",
    "decoder_inputs_data = decoder_inputs_data[:, :-1]\n",
    "\n",
    "decoder_output = np.array(dec).reshape(220000, 28)\n",
    "decoder_output = decoder_output[:, 1:]\n",
    "decoder_target_data = np.expand_dims(decoder_output, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:27.011512Z",
     "iopub.status.busy": "2024-06-12T02:59:27.011235Z",
     "iopub.status.idle": "2024-06-12T02:59:27.197539Z",
     "shell.execute_reply": "2024-06-12T02:59:27.196701Z",
     "shell.execute_reply.started": "2024-06-12T02:59:27.011489Z"
    }
   },
   "outputs": [],
   "source": [
    "#This cell take care of preparing test data\n",
    "encoder_inputs_data_test = np.array(enc_test).reshape(21216, 28)\n",
    "encoder_inputs_data_test = encoder_input_preparation(encoder_inputs_data_test)\n",
    "\n",
    "decoder_inputs_data_test = np.array(dec_test).reshape(21216, 28)\n",
    "decoder_inputs_data_test = decoder_input_preparation(decoder_inputs_data_test)\n",
    "decoder_inputs_data_test = decoder_inputs_data_test[:, :-1]\n",
    "\n",
    "decoder_output_test = np.array(dec_test).reshape(21216, 28)\n",
    "decoder_output_test = decoder_output_test[:, :-1]\n",
    "#the reason that I exoanded decoder output dimension is based on the way encoder-decoder work\n",
    "#in the inference part, decoder values are produced token by token, so we expand the dimension so that we will be able \n",
    "#to generate it token by token\n",
    "decoder_output_test = np.expand_dims(decoder_output_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:27.199146Z",
     "iopub.status.busy": "2024-06-12T02:59:27.198720Z",
     "iopub.status.idle": "2024-06-12T02:59:27.205795Z",
     "shell.execute_reply": "2024-06-12T02:59:27.204837Z",
     "shell.execute_reply.started": "2024-06-12T02:59:27.199114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  47, 2756,  685,   21,   16, 6775,   11,   10,  224,  679, 6429,\n",
       "        969,  114, 1112, 3941,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we can se a sample of encoder input which does not have start(3) and end(2) indexes\n",
    "encoder_inputs_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:28.256647Z",
     "iopub.status.busy": "2024-06-12T02:59:28.255912Z",
     "iopub.status.idle": "2024-06-12T02:59:28.262697Z",
     "shell.execute_reply": "2024-06-12T02:59:28.261723Z",
     "shell.execute_reply.started": "2024-06-12T02:59:28.256617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3, 3941, 6775,  114,  685,   21, 6429,   16, 1112,  969,   47,\n",
       "         10,  224,  679,   11, 2756,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoder input has start(3) index as it should \n",
    "decoder_inputs_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:30.044554Z",
     "iopub.status.busy": "2024-06-12T02:59:30.044182Z",
     "iopub.status.idle": "2024-06-12T02:59:30.051194Z",
     "shell.execute_reply": "2024-06-12T02:59:30.050277Z",
     "shell.execute_reply.started": "2024-06-12T02:59:30.044503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3941],\n",
       "       [6775],\n",
       "       [ 114],\n",
       "       [ 685],\n",
       "       [  21],\n",
       "       [6429],\n",
       "       [  16],\n",
       "       [1112],\n",
       "       [ 969],\n",
       "       [  47],\n",
       "       [  10],\n",
       "       [ 224],\n",
       "       [ 679],\n",
       "       [  11],\n",
       "       [2756],\n",
       "       [   2],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0]], dtype=int32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters:**\n",
    "* Reasonable value for embed_dim is either 128 or 256. However, when we choose 256, it increase the number of parameters significanlty(arround two times) but the result compared to the network with 128 embed_dim was almost the same. Hence, I have decided to choose 128 because the training time, testing time were significanlty better and almost the same result\n",
    "\n",
    "* Loss is Sparse Categorical Cross Entroppy because our label are integers and they are not in the form of One-hot encoding. Thus, we cannot use Categorical Cross Entropy and we should use Sparse version.\n",
    "\n",
    "\n",
    "* Optimizer is Adam, firstly because of the all works so far in seq2seq problems have used this optimizer and secondly, the results of this optimizer compared to RMSprop was better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T02:59:33.518635Z",
     "iopub.status.busy": "2024-06-12T02:59:33.518003Z",
     "iopub.status.idle": "2024-06-12T02:59:33.523328Z",
     "shell.execute_reply": "2024-06-12T02:59:33.522400Z",
     "shell.execute_reply.started": "2024-06-12T02:59:33.518604Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocabulary_size()\n",
    "max_length = sentences.shape[1]\n",
    "embed_dim = 128\n",
    "lstm_units = 256\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:07:32.626067Z",
     "iopub.status.busy": "2024-06-12T03:07:32.625686Z",
     "iopub.status.idle": "2024-06-12T03:07:32.962111Z",
     "shell.execute_reply": "2024-06-12T03:07:32.961263Z",
     "shell.execute_reply.started": "2024-06-12T03:07:32.626037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_57\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_57\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_40        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_50        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_41        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ not_equal_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ lstm_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │ lstm_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_51        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_20 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │ lstm_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │ not_equal_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_40        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,280,000\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_50        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_41        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,280,000\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_66 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ not_equal_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_67 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ lstm_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │ lstm_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_51        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_20 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │  \u001b[38;5;34m5,130,000\u001b[0m │ lstm_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │ not_equal_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,315,536</span> (39.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,315,536\u001b[0m (39.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,315,536</span> (39.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,315,536\u001b[0m (39.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_lstm_model(vocab_size, max_length, embed_dim=128, lstm_units=512, dropout_rate=0.2):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_length,), dtype='int32', name='encoder_inputs')\n",
    "    encoder_embedding = Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=max_length, mask_zero=True)(encoder_inputs)\n",
    "    encoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True, recurrent_dropout=dropout_rate, use_cudnn=False)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Decoder\n",
    "    #Decoder input data is shifted. This is the reason of max_length - 1\n",
    "    decoder_inputs = Input(shape=(max_length-1,), dtype='int32', name='decoder_inputs')\n",
    "    decoder_embedding = Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=max_length-1, mask_zero=True)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True, recurrent_dropout=dropout_rate, use_cudnn=False)\n",
    "    #in decoder output in this architecture, the states of the LSTMs are not important and we do not use them.\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return model\n",
    "\n",
    "vocab_size = 10000  # Update this according to your tokenizer\n",
    "max_length = train_data.shape[1]  # Assuming all sequences have the same length\n",
    "model = build_lstm_model(vocab_size, max_length = 28)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:07:39.753684Z",
     "iopub.status.busy": "2024-06-12T03:07:39.752704Z",
     "iopub.status.idle": "2024-06-12T03:44:51.700855Z",
     "shell.execute_reply": "2024-06-12T03:44:51.699790Z",
     "shell.execute_reply.started": "2024-06-12T03:07:39.753649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 32ms/step - loss: 4.7572\n",
      "Epoch 2/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 32ms/step - loss: 2.1780\n",
      "Epoch 3/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 32ms/step - loss: 1.2490\n",
      "Epoch 4/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 32ms/step - loss: 0.8377\n",
      "Epoch 5/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 32ms/step - loss: 0.6387\n",
      "Epoch 6/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 32ms/step - loss: 0.5180\n",
      "Epoch 7/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 32ms/step - loss: 0.4369\n",
      "Epoch 8/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 32ms/step - loss: 0.3800\n",
      "Epoch 9/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 32ms/step - loss: 0.3359\n",
      "Epoch 10/10\n",
      "\u001b[1m6875/6875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 32ms/step - loss: 0.3007\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [encoder_inputs_data, decoder_inputs_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:45:19.606972Z",
     "iopub.status.busy": "2024-06-12T03:45:19.606612Z",
     "iopub.status.idle": "2024-06-12T03:45:19.865648Z",
     "shell.execute_reply": "2024-06-12T03:45:19.864739Z",
     "shell.execute_reply.started": "2024-06-12T03:45:19.606945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:45:27.612758Z",
     "iopub.status.busy": "2024-06-12T03:45:27.612293Z",
     "iopub.status.idle": "2024-06-12T03:45:27.617143Z",
     "shell.execute_reply": "2024-06-12T03:45:27.616058Z",
     "shell.execute_reply.started": "2024-06-12T03:45:27.612728Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_10epoch = history.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why we need Inference?**\n",
    "\n",
    "* During training, we are aware of the decoder input. On the other hand, when the model face new data, it has no idea what the decoder input is. Thus, we create inference part so:\n",
    "1. we give shuffled data to encoder to generate context\n",
    "2. we use the context provided by encoder, and start token as the first input to decoder to generate the second decoder token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:45:39.038126Z",
     "iopub.status.busy": "2024-06-12T03:45:39.037286Z",
     "iopub.status.idle": "2024-06-12T03:45:39.055761Z",
     "shell.execute_reply": "2024-06-12T03:45:39.054818Z",
     "shell.execute_reply.started": "2024-06-12T03:45:39.038095Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoder_inputs = model.input[0]  # Encoder input from the trained model\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[4].output  # LSTM output and states\n",
    "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
    "\n",
    "decoder_inputs = model.input[1]  # Decoder input from the trained model\n",
    "decoder_state_input_h = Input(shape=(512,), name='decoder_state_input_h')\n",
    "decoder_state_input_c = Input(shape=(512,), name='decoder_state_input_c')\n",
    "decoder_embedding = model.layers[3](decoder_inputs)\n",
    "decoder_lstm = model.layers[5]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
    ")\n",
    "decoder_dense = model.layers[6]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs] + [state_h_dec, state_c_dec]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:45:41.070462Z",
     "iopub.status.busy": "2024-06-12T03:45:41.069754Z",
     "iopub.status.idle": "2024-06-12T03:45:41.078208Z",
     "shell.execute_reply": "2024-06-12T03:45:41.077231Z",
     "shell.execute_reply.started": "2024-06-12T03:45:41.070433Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    #verbose is 0 so that when predicting, the notebook will not be filled with progess bars\n",
    "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq, verbose =0)\n",
    "\n",
    "    #we create a first token as start to give to decoder\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer('<start>')\n",
    "\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + [state_h, state_c]\n",
    "        )\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tokenizer.get_vocabulary()[sampled_token_index]\n",
    "\n",
    "        # Exit condition: either hit max length or find stop token\n",
    "        if sampled_token == '<end>' or len(decoded_sentence) > 28:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "            # Update the target sequence (of length 1)\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "            # Update states\n",
    "            state_h, state_c = h, c\n",
    "\n",
    "    return decoded_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:45:42.710310Z",
     "iopub.status.busy": "2024-06-12T03:45:42.709443Z",
     "iopub.status.idle": "2024-06-12T03:45:42.715002Z",
     "shell.execute_reply": "2024-06-12T03:45:42.714080Z",
     "shell.execute_reply.started": "2024-06-12T03:45:42.710279Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(seq):\n",
    "    seq = np.array(seq).reshape(1, 28)\n",
    "    preds = decode_sequence(seq)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:45:43.786703Z",
     "iopub.status.busy": "2024-06-12T03:45:43.785813Z",
     "iopub.status.idle": "2024-06-12T03:45:45.632679Z",
     "shell.execute_reply": "2024-06-12T03:45:45.631704Z",
     "shell.execute_reply.started": "2024-06-12T03:45:43.786672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = prediction(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:45:51.622883Z",
     "iopub.status.busy": "2024-06-12T03:45:51.622204Z",
     "iopub.status.idle": "2024-06-12T03:45:51.628833Z",
     "shell.execute_reply": "2024-06-12T03:45:51.627841Z",
     "shell.execute_reply.started": "2024-06-12T03:45:51.622852Z"
    }
   },
   "outputs": [],
   "source": [
    "detokenized_x = detokenizer(x)\n",
    "detokenized_y = detokenizer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T03:45:53.113662Z",
     "iopub.status.busy": "2024-06-12T03:45:53.112974Z",
     "iopub.status.idle": "2024-06-12T03:45:53.117918Z",
     "shell.execute_reply": "2024-06-12T03:45:53.117049Z",
     "shell.execute_reply.started": "2024-06-12T03:45:53.113631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tested truth value is :\n",
      " <start> wind energy is the one of the most inexpensive forms of energy on the market <end> \n",
      " The predicted value is:\n",
      " energy is one of the most important\n"
     ]
    }
   ],
   "source": [
    "print(f'the tested truth value is :\\n {detokenized_y[0]} \\n The predicted value is:\\n {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model could order part of the sentence with the correct position of 'noun', 'to be' and rest of the sentence. With playing with hyperparameters and training the model for a couple of more epoch, maybe we could get a little better result but the difference is not that much. Hence, in another notebook, I am going to train a transformer for this task to see the difference between the performance of transformer and this LSTM based model. But I believe for a model with just 10 milion parameters, this model has showed an acceptable perfromance"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
